# ETL Pipeline - PelÃ­culas Dataset

## ğŸ“‹ DescripciÃ³n
Pipeline ETL implementado con Apache Airflow para procesar y transformar el dataset de pelÃ­culas "Latest 2025 movies Datasets". El pipeline sigue la arquitectura medallion (Bronze â†’ Silver â†’ Gold) para garantizar calidad y trazabilidad de los datos.

## âœ… Resumen de lo Realizado

### RefactorizaciÃ³n y Mejora de Estructura
- âœ… **CentralizaciÃ³n de configuraciÃ³n**: CreaciÃ³n de `config.py` con todas las constantes (rutas, logging)
- âœ… **ModularizaciÃ³n de scripts**: ActualizaciÃ³n de `extract_bronze.py`, `extract_silver.py` y `extract_gold.py` para importar desde `config.py`
- âœ… **EliminaciÃ³n de duplicidad**: Removidos hardcoded paths de cada script
- âœ… **Correcta gestiÃ³n de imports**: Scripts en `dags/scripts/` importan correctamente desde `dags/config.py`

### OptimizaciÃ³n del DAG
- âœ… **ActualizaciÃ³n a Airflow 2.x+**: Cambio de `schedule_interval` a `schedule`
- âœ… **Removido parÃ¡metro deprecado**: Eliminado `provide_context=True` incompatible con versiÃ³n actual
- âœ… **Mejor naming**: Nombres descriptivos en task_ids (`extract_bronze`, `transform_silver`, `load_gold`)
- âœ… **Default args centralizados**: ConfiguraciÃ³n comÃºn para todas las tareas
- âœ… **Metadata mejorada**: Agregados descripciÃ³n y tags al DAG

### ValidaciÃ³n y EjecuciÃ³n
- âœ… **DAG funcional**: Pipeline ejecutÃ¡ndose correctamente en Docker Compose
- âœ… **Tres etapas trabajando**: Bronze â†’ Silver â†’ Gold en secuencia

### DocumentaciÃ³n y Versionamiento
- âœ… **README completo**: DocumentaciÃ³n detallada del proyecto
- âœ… **Repositorio Git**: Proyecto subido a GitHub con `.gitignore`
- âœ… **Commits estructurados**: Historial claro de cambios

## ğŸ—ï¸ Estructura del Proyecto

```
Entregable-3/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ etl-peliculas-dag.py      # DAG principal de Airflow
â”‚   â”œâ”€â”€ config.py                 # ConfiguraciÃ³n centralizada
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ extract_bronze.py     # ExtracciÃ³n de datos
â”‚       â”œâ”€â”€ extract_silver.py     # TransformaciÃ³n y limpieza
â”‚       â””â”€â”€ extract_gold.py       # Carga de mÃ©tricas de negocio
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ origin/                   # Datos originales (CSV)
â”‚   â”œâ”€â”€ bronze/                   # Capa Bronze (datos sin procesar)
â”‚   â”œâ”€â”€ silver/                   # Capa Silver (datos limpios)
â”‚   â””â”€â”€ gold/                     # Capa Gold (datos finales)
â”œâ”€â”€ logs/                         # Logs de ejecuciÃ³n de Airflow
â”œâ”€â”€ docker-compose.yaml           # ConfiguraciÃ³n de Docker
â”œâ”€â”€ config/
â”‚   â””â”€â”€ airflow.cfg              # ConfiguraciÃ³n de Airflow
â””â”€â”€ README.md                     # Este archivo
```

## ğŸš€ Inicio RÃ¡pido

### Requisitos
- Docker y Docker Compose instalados
- Python 3.8+ (para desarrollo local)

### InstalaciÃ³n y EjecuciÃ³n

1. **Clonar o descargar el repositorio**
```bash
git clone https://github.com/TU_USUARIO/Entregable-3.git
cd Entregable-3
```

2. **Iniciar Airflow con Docker**
```powershell
docker-compose up -d
```

3. **Acceder a Airflow UI**
```
http://localhost:8080
```

4. **Activar el DAG**
   - En la UI de Airflow, busca `cem_pipeline`
   - Haz clic en el toggle para activarlo
   - Haz clic en "Trigger DAG" para ejecutarlo manualmente

### Detener Airflow
```powershell
docker-compose down
```

## ğŸ“Š Pipeline DAG: `cem_pipeline`

El DAG ejecuta tres tareas en secuencia:

### 1. **extract_bronze** 
- Lee el CSV original: `Latest 2025 movies Datasets.csv`
- Valida que el archivo exista
- Limpia espacios en blanco
- Guarda en `data/bronze/bronze_data.csv`

### 2. **transform_silver**
- Lee datos desde Bronze
- Limpia datos faltantes
- Normaliza tipos de datos
- Elimina duplicados
- Valida rangos de valores
- Guarda en `data/silver/silver_data.csv`

### 3. **load_gold**
- Lee datos desde Silver
- Crea nuevas columnas de negocio (aÃ±o, mes, categorÃ­as)
- Genera estadÃ­sticas por idioma y aÃ±o
- Clasifica pelÃ­culas por calificaciÃ³n y popularidad
- Guarda en `data/gold/gold_data.csv`

## âš™ï¸ ConfiguraciÃ³n

### Rutas de Datos (config.py)
```python
ORIGIN_PATH = '/opt/airflow/data/origin/Latest 2025 movies Datasets.csv'
BRONZE_PATH = '/opt/airflow/data/bronze/bronze_data.csv'
SILVER_PATH = '/opt/airflow/data/silver/silver_data.csv'
GOLD_PATH = '/opt/airflow/data/gold/gold_data.csv'
```

### ProgramaciÃ³n
- **Frecuencia**: Diariamente (`@daily`)
- **Hora**: A las 00:00 UTC (configurable en Airflow)
- **Reintentos**: 1 intento fallido = reintentar en 5 minutos

## ğŸ“ Variables de Entorno

Si necesitas cambiar configuraciones, edita `config.py`:

```python
# Logging
LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"
TIMESTAMP = datetime.now().isoformat()
```

## ğŸ”§ Desarrollo Local (sin Docker)

Si prefieres ejecutar localmente:

```powershell
# Activar entorno virtual
.venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt

# Inicializar Airflow
airflow db init

# Crear usuario
airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com

# Iniciar webserver (en una terminal)
airflow webserver --port 8080

# Iniciar scheduler (en otra terminal)
airflow scheduler
```

## ğŸ“ˆ Monitoreo

En la UI de Airflow puedes:
- Ver el estado de las ejecuciones
- Consultar logs de cada tarea
- Monitorear tiempos de ejecuciÃ³n
- Reejecutar tareas fallidas

## ğŸ› Troubleshooting

### Error: "DAG not found"
- Verifica que `etl-peliculas-dag.py` estÃ© en la carpeta `dags/`
- Reinicia los contenedores: `docker-compose restart`

### Error: "File not found"
- Verifica que el archivo CSV estÃ¡ en `data/origin/`
- Comprueba las rutas en `config.py`

### Error: "Import error"
- Verifica que todos los scripts estÃ¡n en `dags/scripts/`
- Comprueba que `config.py` estÃ¡ en `dags/`

## ğŸ“š Recursos

- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Docker Documentation](https://docs.docker.com/)

## ğŸ‘¤ Autor
Jhersson Cruz - Ingeniero de Sistemas

## ğŸ“„ Licencia
MIT
